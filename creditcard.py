# -*- coding: utf-8 -*-
"""CreditCard.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14nBISIMofM8ATCk4_RZfhmspIvTW7r7-
"""

import numpy as np #for making arrays
import pandas as pd #to make dataframes /structed table for analysis
from sklearn.model_selection import train_test_split #function to split data into training and testing data
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score #to check the performance of the model

#load the dataset to pandas dataframe
credit_card_data=pd.read_csv('/creditcard.csv')

#print first 5 rows
credit_card_data.head()

credit_card_data.tail()

#dataset info
credit_card_data.info()

#checking the number of missingvalues in each column
credit_card_data.isnull().sum()

#distribution of legit transcations & fradulent transactions
credit_card_data['Class'].value_counts()

'''
#dataset is highly unbalanced
0--> Normal Transaction
1--> fraudulent transcation
'''
#separating the data for analysis
legit=credit_card_data[credit_card_data.Class ==0]
fraud=credit_card_data[credit_card_data.Class ==1]

print(legit.shape)
print(fraud.shape)

#staistical measures of data
legit.Amount.describe()

fraud.Amount.describe()

#compare the values for both transactions
credit_card_data.groupby('Class').mean()

"""Under-sampling Build a sample dataset containing similar distribution of normal transactions and fraudlent transactions No of fraudlent transactions-->56"""

legit_sample=legit.sample(n=56)

#Concatenate two dataframes
new_dataset=pd.concat([legit_sample,fraud],axis=0)#0 means row

new_dataset.head()

new_dataset.tail()

new_dataset['Class'].value_counts()

new_dataset.groupby('Class').mean()

#spliting the data into features & targets
X=new_dataset.drop(columns='Class',axis=1)
Y=new_dataset['Class']

print(X)

print(Y)

"""split the data into Training data & testing data


"""

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)

print(X.shape,X_train.shape,X_test.shape)

"""model Training
Logistic regression

"""

model = LogisticRegression()

#training the logistic regression model with Training data X_train-->features of training data Y-->train corresponding labels (0/1)
model.fit(X_train, Y_train)

Model Evaluation
Accuracy score

#accuracy on training data
X_train_prediction =model.predict(X_train)
training_data_accuracy=accuracy_score(X_train_prediction,Y_train)

print('Accuracy on Training_data_accuracy:',training_data_accuracy)

#accuracy on test data
X_test_prediction =model.predict(X_test)
test_data_accuracy=accuracy_score(X_test_prediction,Y_test)

print('Accuracy score on test data:',test_data_accuracy)

